# Quick Start Guide - MVP Engenharia de Dados

## ğŸš€ InÃ­cio RÃ¡pido

### 1. InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/ricferal/mvpPucEngenhariaDados.git
cd mvpPucEngenhariaDados

# OpÃ§Ã£o A: Usar o script de setup (recomendado)
bash setup.sh

# OpÃ§Ã£o B: InstalaÃ§Ã£o manual
pip install -r requirements.txt
python src/generate_sample_data.py
```

### 2. Executar o Pipeline

```bash
# Executar o pipeline completo
python src/pipeline.py

# Executar exemplos
python example.py
```

### 3. Com Docker

```bash
# Iniciar todos os serviÃ§os
docker-compose up -d

# Ver logs
docker-compose logs -f

# Parar serviÃ§os
docker-compose down
```

## ğŸ“Š Estrutura dos Dados

### Entrada (data/raw/)
- Dados brutos de fontes externas
- Formato: CSV, JSON, APIs

### SaÃ­da (data/processed/)
- Dados limpos e transformados
- Formato: CSV, JSON, Parquet

## ğŸ”§ Exemplos de Uso

### Exemplo 1: Pipeline BÃ¡sico

```python
from src.pipeline import ETLPipeline

pipeline = ETLPipeline()
pipeline.run_pipeline(
    source_path="data/raw/sample_data.csv",
    output_path="data/processed/output.csv"
)
```

### Exemplo 2: MÃ³dulos Individuais

```python
from src.extract.extractor import DataExtractor
from src.transform.transformer import DataTransformer
from src.load.loader import DataLoader

# ExtraÃ§Ã£o
extractor = DataExtractor()
df = extractor.extract_from_csv("data/raw/sample_data.csv")

# TransformaÃ§Ã£o
transformer = DataTransformer()
df = transformer.remove_duplicates(df)
df = transformer.handle_missing_values(df, strategy='drop')

# Carga
loader = DataLoader()
loader.load_to_csv(df, "data/processed/output.csv")
```

### Exemplo 3: Com ConfiguraÃ§Ã£o

```python
from src.pipeline import ETLPipeline

pipeline = ETLPipeline(config_path="config/pipeline_config.yaml")
pipeline.run_pipeline(
    source_path="data/raw/sample_data.csv",
    output_path="data/processed/output.csv"
)
```

## ğŸ¯ Funcionalidades Principais

### Extract (ExtraÃ§Ã£o)
- `extract_from_csv()` - Extrair de CSV
- `extract_from_json()` - Extrair de JSON
- `extract_from_api()` - Extrair de API REST

### Transform (TransformaÃ§Ã£o)
- `remove_duplicates()` - Remover duplicatas
- `handle_missing_values()` - Tratar valores faltantes
- `normalize_columns()` - Normalizar dados
- `filter_data()` - Filtrar dados
- `aggregate_data()` - Agregar dados

### Load (Carga)
- `load_to_csv()` - Carregar para CSV
- `load_to_json()` - Carregar para JSON
- `load_to_parquet()` - Carregar para Parquet
- `load_to_database()` - Carregar para banco de dados

## ğŸ“ˆ Fluxo do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Extract   â”‚ â”€â”€â”€> â”‚  Transform   â”‚ â”€â”€â”€> â”‚    Load     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                      â”‚                      â”‚
     â”‚                      â”‚                      â”‚
  CSV/JSON/API       Clean/Filter/Agg      CSV/JSON/DB
```

## ğŸ” Logs e Monitoramento

Os logs sÃ£o gerados automaticamente:

```
INFO - Starting ETL Pipeline
INFO - Extracted 1050 rows from CSV
INFO - Removed 43 duplicate rows
INFO - Successfully loaded 918 rows
INFO - Pipeline completed in 0.01 seconds
```

## âš™ï¸ ConfiguraÃ§Ã£o

Edite `config/pipeline_config.yaml` para customizar:

```yaml
transform:
  remove_duplicates: true
  missing_values:
    strategy: drop  # ou fill, ffill, bfill

load:
  output_format: csv  # ou json, parquet, database
```

## ğŸ› Troubleshooting

### Erro: Module not found
```bash
pip install -r requirements.txt
```

### Erro: Sample data not found
```bash
python src/generate_sample_data.py
```

### Erro: Permission denied
```bash
chmod +x setup.sh
```

## ğŸ“š DocumentaÃ§Ã£o Completa

Consulte o [README.md](README.md) para documentaÃ§Ã£o detalhada.

## ğŸ¤ Suporte

Para dÃºvidas ou problemas:
1. Verifique a documentaÃ§Ã£o
2. Execute os exemplos
3. Verifique os logs

---

**MVP Engenharia de Dados - PUC**
